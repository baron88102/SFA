rm(list = ls())
gc(reset = TRUE)

library(TSM1)
library(Rcpp)

# Load C++ function
Rcpp::sourceCpp(file = "sfa.cpp")


# This test verifies that the sliding window runs for the entire
# string and that all words are calculated.
data <- ar_data
serie <- data$Close[1:100]
sw <- 20:100
wl <- 20
as <- 5
validated <- TRUE
for (i in 1:length(sw)) {
  words <- fn_sfa2(data = serie,
                  sliding_window = sw[i],
                  word_length = wl,
                  alphabet_size = as)
  empty_words <- is.na(match("", words))
  total_words <- length(serie) - sw[i] + 1
  equal_size <- total_words == length(words)
  comparing <- empty_words & equal_size
  validated <- validated & comparing
}

print(paste0("validated must be TRUE: ", validated))



# This test verifies that the original SFA words and SFA words in the
# package match.
# Check when the series is normalized and when it is not normalized
# General parameters
wl <- 10
as <- 6

####### Calculate the word when apply_znorm=FALSE, norm_mean=FALSE
# Word calculates with original code
path <- "./data/italypowerdemand/italypowerdemand_one_serie_words.csv"
words_df <- read.csv(path)
original_word <- words_df$word

# Calculate SFA
data_df <- read.csv("./data/italypowerdemand/italypowerdemand_one_serie.csv")
serie_without_normalize <- data_df$serie
word_without_normalize <- fn_sfa2(data = serie_without_normalize,
                                 sliding_window = length(serie_without_normalize),
                                 word_length = wl,
                                 alphabet_size = as,
                                 norm_mean = FALSE,
                                 apply_znorm = FALSE)
equal_without_normalized <- (original_word == word_without_normalize)


####### Calculate the word when apply_znorm=TRUE, norm_mean=TRUE
# The original word is generated by normalizing the string passed
# to the function with respect to the mean.
path <- "./data/italypowerdemand/italypowerdemand_one_serie_words_normalized.csv"
words_df_normalized <- read.csv(path)
original_word_normalized <- words_df_normalized$word
word_normalize <- fn_sfa2(data = serie_without_normalize,
                   sliding_window = length(serie_without_normalize),
                   word_length = wl,
                   alphabet_size = as,
                   norm_mean = TRUE,
                   apply_znorm = TRUE)
equal_normalized <- (original_word_normalized == word_normalize)

# Serie from TSM1 stock$Close (without normalize)
comparing <- equal_without_normalized & equal_normalized

print(paste0("comparing must be TRUE: ", validated))



# Verify words for differents series of same length - Time series
# are not normalized.
# The results must be equal above 98%. With the previous unit tests
# it has been seen that there may be a difference due to the precision
precision_umbral <- 0.98
wl <- 10
as <- 6

filename_path <- "./data/italypowerdemand/italypowerdemand_train.csv"
series <- read.csv(file = paste(filename_path, sep = ""),
                   header = FALSE)
series <- series[, -1]

filename_path <- "./data/italypowerdemand/italypowerdemand_train_words.csv"
series_words_original <- read.csv(file = paste(filename_path, sep = ""),
                                  header = TRUE)

# We calculate all SFA words
words <- c()
for (i in 1:nrow(series)) {
  serie <- as.numeric(series[i, ])
  words[i] <- fn_sfa2(data = serie,
                         sliding_window = length(serie),
                         word_length = wl,
                         alphabet_size = as,
                         norm_mean = FALSE,
                         apply_znorm = FALSE)
}

# We verify that all the words coincide and those that do not coincide,
# the position where they have a difference is calculated.
is_valid <- TRUE
result <- data.frame(original = series_words_original$word,
                     sfa = words)
result <- cbind(result, diff = result$original == result$sfa)
table(result$diff)
success <- table(result$diff)["TRUE"] / nrow(series)

print(paste0("success must be grether equal 98%: ", success))




# Verify words for differents series - Time series are normalized
# The results must be equal above 98%. With the previous unit tests
# it has been seen that there may be a difference due to the precision
precision_umbral <- 0.98
wl <- 10
as <- 6

filename_path <- "./data/italypowerdemand/italypowerdemand_train.csv"
series <- read.csv(file = paste(filename_path, sep = ""),
                   header = FALSE)
series <- series[, -1]

filename_path <- "./data/italypowerdemand/italypowerdemand_train_words_normalized.csv"
series_words_original <- read.csv(file = paste(filename_path, sep = ""),
                                  header = TRUE)

# We calculate all SFA words
words <- c()
for (i in 1:nrow(series)) {
  serie <- as.numeric(series[i, ])
  words[i] <- fn_sfa2(data = serie,
                     sliding_window = length(serie),
                     word_length = wl,
                     alphabet_size = as,
                     norm_mean = TRUE,
                     apply_znorm = TRUE)
}

# We verify that all the words coincide and those that do not coincide,
# the position where they have a difference is calculated.
is_valid <- TRUE
result <- data.frame(original = series_words_original$word,
                     sfa = words)
result <- cbind(result, diff = result$original == result$sfa)
success <- table(result$diff)["TRUE"] / nrow(series)

print(paste0("success must be grether equal 98%: ", success))



# This test verifies a grid of parameters
# For this test, it is verified that when the series is not standardized, 
# the results are the original ones.
# This is due to the precision of the different languages
# Results above 98%
  # Aceptance threshold
  umbral <- 0.98

  # Load original words
  original_words <- read.csv("./data/words_grid_znorm_false.csv")

  serie <- ar_data$Close[1:1000]

  # Define grid
  sw_s <- c(30, 120, 200)
  wl_s <- c(3, 4, 5, 6, 7, 8, 9, 10)
  as_s <- c(3, 4, 5, 6, 7, 8, 9, 10)
  
  comparing <- list()
  index <- 1
  for (i in 1:length(sw_s)) {
    sw <- sw_s[i]
    for (j in 1:length(wl_s)) {
      wl <- wl_s[j]
      for (k in 1:length(as_s)) {
        as <- as_s[k]
        words <- fn_sfa2(data = serie,
                        sliding_window = sw,
                        word_length = wl,
                        alphabet_size = as,
                        norm_mean = FALSE,
                        apply_znorm = FALSE)
        words_original <- original_words[1:length(words),
                                         paste("sw", sw, "wl", wl, "as", as, sep = "_")]
        comparing[[index]] <- words == words_original
        index <- index + 1
      }
    }
  }
  names(comparing) <- names(original_words)

  # Calculate general sucessfull
  comparing_table <- lapply(comparing, table)
  f <- function(x) {
    return(x["TRUE"])
  }
  comparing_sucessfull <- lapply(comparing_table, FUN = f)
  comparing_sucessfull <- sum(as.numeric(comparing_sucessfull))

  total <- lapply(comparing_table, sum)
  total <- sum(as.numeric(total))

  sucessfull <- comparing_sucessfull / total

  print(paste0("success must be grether equal 98%: ", success))


# # This test verifies a grid of parameters
# # Para esta prueba se verifica que cuando no se estandariza la serie los resultados son los originales a los mismos.
# # Esto es debido a la precisiÃ²n de los diferentes lenguajes
#   # Aceptance threshold
#   umbral <- 0.98
# 
#   # Load original words
#   original_words <- read.csv("./data/words_grid_znorm_true.csv")
# 
#   # series <- read.csv("ar_data_sw_200.csv")
#   # serie <- as.numeric(series[1, -1])
#   serie <- ar_data$Close[1:1000] # 1000
#   # serie <- (serie - mean(serie))/sd(serie)
# 
#   # Define grid
#   sw_s <- c(30, 120, 200)  # [30, 120, 200] 1000-500 not working
#   wl_s <- c(3, 4, 5, 6, 7, 8, 9, 10) #c(3, 4, 5, 6, 7, 8, 9, 10)
#   as_s <- c(3, 4, 5, 6, 7, 8, 9, 10) #c(3, 4, 5, 6, 7, 8, 9, 10)
# 
#   comparing <- list()
#   index <- 1
#   for (i in 1:length(sw_s)) {
#     sw <- sw_s[i]
#     for (j in 1:length(wl_s)) {
#       wl <- wl_s[j]
#       for (k in 1:length(as_s)) {
#         as <- as_s[k]
#         words <- fn_sfa2(data = serie,
#                         sliding_window = sw,
#                         word_length = wl,
#                         alphabet_size = as,
#                         norm_mean = TRUE,
#                         apply_znorm = TRUE)
#         words_original <- original_words[1:length(words), paste("sw", sw, "wl", wl, "as", as, sep = "_")]
#         comparing[[index]] <- words == words_original
#         index <- index + 1
#       }
#     }
#   }
#   names(comparing) <- names(original_words)
# 
#   # Calculate general sucessfull
#   comparing_table <- lapply(comparing, table)
#   f <- function(x) {
#     return(x["TRUE"])
#   }
#   comparing_sucessfull <- lapply(comparing_table, FUN = f)
#   comparing_sucessfull <- sum(as.numeric(comparing_sucessfull))
# 
#   total <- lapply(comparing_table, sum)
#   total <- sum(as.numeric(total))
# 
#   sucessfull <- comparing_sucessfull / total
#
# print(paste0("success must be grether equal 98%: ", success))